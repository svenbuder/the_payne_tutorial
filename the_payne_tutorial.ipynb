{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ec9d73",
   "metadata": {},
   "source": [
    "# The Payne Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a85822",
   "metadata": {},
   "source": [
    "Follow the instructions from https://github.com/tingyuansen/The_Payne/tree/master:\n",
    "\n",
    "\n",
    "```bash\n",
    "cd /path/were/you/want/to/install/The_Payne/\n",
    "git clone https://github.com/tingyuansen/The_Payne.git\n",
    "cd The_Payne\n",
    "python setup.py install\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79740f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19f7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from The_Payne import training\n",
    "from The_Payne import utils\n",
    "from The_Payne import spectral_model\n",
    "\n",
    "# \"\"\"\n",
    "# Changes that need to be made to training.py in The_Payne if no CUDA is available\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "    perm = perm.cuda()\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    perm_valid = perm_valid.cuda()\n",
    "\"\"\"\n",
    "\n",
    "# I have also adjusted the output names to be a keyword argument.\n",
    "# If you want that too, you would need to search->replace:\n",
    "\"\"\"\n",
    "def neural_net(training_labels, training_spectra, validation_labels, validation_spectra,\\\n",
    "         num_neurons = 300, num_steps=1e4, learning_rate=1e-4, batch_size=512,\\\n",
    "         num_features = 64*5, mask_size=11, num_pixel=7214,\n",
    "         training_loss_name = \"training_loss.npz\",\n",
    "         payne_model_name = \"NN_normalized_spectra.npz\"\n",
    "         ):\n",
    "\"training_loss.npz\" -> training_loss_name\n",
    "\"NN_normalized_spectra.npz\" -> payne_model_name\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c002a",
   "metadata": {},
   "source": [
    "# Preparing example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330c1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_again = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a886306",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_again:\n",
    "    galah_dr3 = Table.read('/Users/buder/GALAH_DR3/catalogs/GALAH_DR3_main_allstar_v2.fits')\n",
    "\n",
    "    elements_to_fit = [\n",
    "    #     'Li','C',\n",
    "        'O','Na','Mg','Al','Si',\n",
    "        'K','Ca','Sc','Ti','V','Cr','Mn','Co','Ni','Cu','Zn',\n",
    "    #     'Rb','Sr',\n",
    "        'Y',\n",
    "    #     'Zr','Mo','Ru',\n",
    "        'Ba','La',    \n",
    "    #     'Ce','Nd','Sm',\n",
    "        'Eu'\n",
    "    ]\n",
    "\n",
    "    galah_dr3_subset_giants = galah_dr3[\n",
    "        (galah_dr3['flag_sp'] == 0) &\n",
    "        (galah_dr3['flag_fe_h'] == 0) &\n",
    "        (galah_dr3['snr_c1_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c2_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c3_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c4_iraf'] > 25) &\n",
    "        (galah_dr3['logg'] < 3.) &\n",
    "        np.all([galah_dr3['flag_'+element+'_fe'] == 0 for element in elements_to_fit], axis=0)\n",
    "    ]\n",
    "    galah_dr3_subset_dwarfs = galah_dr3[\n",
    "        (galah_dr3['flag_sp'] == 0) &\n",
    "        (galah_dr3['flag_fe_h'] == 0) &\n",
    "        (galah_dr3['snr_c1_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c2_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c3_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c4_iraf'] > 25) &\n",
    "        (galah_dr3['logg'] > 3.5) &\n",
    "        np.all([galah_dr3['flag_'+element+'_fe'] == 0 for element in elements_to_fit], axis=0)\n",
    "    ]\n",
    "    galah_dr3_subset_subgiants = galah_dr3[\n",
    "        (galah_dr3['flag_sp'] == 0) &\n",
    "        (galah_dr3['flag_fe_h'] == 0) &\n",
    "        (galah_dr3['snr_c1_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c2_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c3_iraf'] > 25) &\n",
    "        (galah_dr3['snr_c4_iraf'] > 25) &\n",
    "        (galah_dr3['logg'] > 3.0) &\n",
    "        (galah_dr3['logg'] < 3.75) &\n",
    "        np.all([galah_dr3['flag_'+element+'_fe'] == 0 for element in elements_to_fit], axis=0)\n",
    "    ]\n",
    "\n",
    "    np.random.seed(712)\n",
    "    random_45_giants_subset = np.random.randint(len(galah_dr3_subset_giants['teff']), size=45)\n",
    "    random_10_subgiants_subset = np.random.randint(len(galah_dr3_subset_subgiants['teff']), size=10)\n",
    "    random_45_dwarfs_subset = np.random.randint(len(galah_dr3_subset_dwarfs['teff']), size=45)\n",
    "\n",
    "    training_label_table = Table()\n",
    "    for key in ['sobject_id','teff','logg','fe_h','vbroad','vmic']:\n",
    "        training_label_table[key] = np.concatenate((\n",
    "            galah_dr3_subset_giants[key][random_45_giants_subset],\n",
    "            galah_dr3_subset_subgiants[key][random_10_subgiants_subset],\n",
    "            galah_dr3_subset_dwarfs[key][random_45_dwarfs_subset],\n",
    "        ))\n",
    "        \n",
    "    training_label_table.write('GALAH_DR3_100_labels.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dffd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sobject_id in training_label_table['sobject_id'][10:20]:\n",
    "#     try:\n",
    "#         os.system('rsync -azu galah@galahobs.datacentral.org.au:/galah/DR3/data/galah/dr3/spectra/'+str(sobject_id)+'1.fits spectra/')\n",
    "#         os.system('rsync -azu galah@galahobs.datacentral.org.au:/galah/DR3/data/galah/dr3/spectra/'+str(sobject_id)+'2.fits spectra/')\n",
    "#         os.system('rsync -azu galah@galahobs.datacentral.org.au:/galah/DR3/data/galah/dr3/spectra/'+str(sobject_id)+'3.fits spectra/')\n",
    "#         os.system('rsync -azu galah@galahobs.datacentral.org.au:/galah/DR3/data/galah/dr3/spectra/'+str(sobject_id)+'4.fits spectra/')\n",
    "#     except:\n",
    "#         print(sobject_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab92a3",
   "metadata": {},
   "source": [
    "# Prepare necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f9481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_label_table = Table.read('GALAH_DR3_100_labels.fits')\n",
    "# put all the labels (i.e. the ones that are not sobject_id) into an array\n",
    "training_set_labels = np.array([list(training_set_label_table[key]) for key in list(training_set_label_table.keys())[1:]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2bd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths_ccds = dict()\n",
    "wavelengths_ccds['1']=np.arange(4715.94,4896.00,0.046)\n",
    "wavelengths_ccds['2']=np.arange(5650.06,5868.25,0.055)\n",
    "wavelengths_ccds['3']=np.arange(6480.52,6733.92,0.064)\n",
    "wavelengths_ccds['4']=np.arange(7693.50,7875.55,0.074)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089809c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_wavelength = np.concatenate(([wavelengths_ccds[ccd] for ccd in ['1','2','3','4']]))\n",
    "training_set_flux = []\n",
    "training_set_flux_uncertainty = []\n",
    "\n",
    "for sobject_id in training_set_label_table['sobject_id'][:20]:\n",
    "    flux_per_spectrum = []\n",
    "    flux_uncertainty_per_spectrum = []\n",
    "    for ccd in ['1','2','3','4']:\n",
    "        fits_file = fits.open('spectra/'+str(sobject_id)+ccd+'.fits')\n",
    "        wavelength_raw = fits_file[4].header['CRVAL1'] + fits_file[4].header['CDELT1'] * np.arange(fits_file[4].header['NAXIS1'])\n",
    "        flux_per_spectrum.append(\n",
    "            np.array(np.interp(wavelengths_ccds[ccd], wavelength_raw, fits_file[4].data).clip(min=0.01,max=1.2))\n",
    "        )\n",
    "        flux_uncertainty_per_spectrum.append(\n",
    "            np.array(np.interp(wavelengths_ccds[ccd], wavelength_raw, fits_file[1].data * fits_file[4].data).clip(min=0.001))\n",
    "        )\n",
    "        fits_file.close()\n",
    "    training_set_flux.append(np.concatenate((flux_per_spectrum)))\n",
    "    training_set_flux_uncertainty.append(np.concatenate((flux_uncertainty_per_spectrum)))\n",
    "\n",
    "training_set_flux = np.array(training_set_flux)\n",
    "training_set_flux_uncertainty = np.array(training_set_flux_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255bceb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3585ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(np.arange(np.shape(training_set_flux)[0]), test_size=0.10, random_state=8876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'galah_tutorial'\n",
    "\n",
    "training.neural_net(\n",
    "    training_labels = training_set_labels[train,:], \n",
    "    training_spectra = training_set_flux[train,:],\n",
    "    validation_labels = training_set_labels[test,:], \n",
    "    validation_spectra = training_set_flux[test,:],\n",
    "    num_neurons=20,\n",
    "    learning_rate=1e-4,\n",
    "    num_steps=1e4,\n",
    "    batch_size=28,\n",
    "    num_pixel=np.shape(training_set_flux[0])[0]\n",
    "    training_loss_name = model_file+'_loss.npz',\n",
    "    payne_model_name = model_file+'.npz'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7f0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
